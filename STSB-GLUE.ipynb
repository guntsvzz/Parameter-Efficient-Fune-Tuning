{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a2dba9d-6db3-4031-bf00-e008d475c9a0",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa36c94-3005-420f-8bc8-264ae6ab96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment this if you are not using AIT proxy...\n",
    "import os\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d68cb4-6529-4b77-adf4-3cc5ff547ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset glue (/home/todsavadt/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 1614.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Three men are playing chess.',\n",
       " 'sentence2': 'Two men are playing chess.',\n",
       " 'label': 2.5999999046325684,\n",
       " 'idx': 3}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "task_name = \"stsb\"\n",
    "datasets = load_dataset(\"glue\", task_name)\n",
    "datasets[\"train\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b62208a5-920f-4915-9a76-16fd0f1a7b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence1', 'sentence2', 'label', 'idx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9ee0ee-3cef-465d-a228-669e6b7e3432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sentence1', 'sentence2')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_to_keys[task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64820316-3e70-4765-a7ed-442f87b49809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='float32', id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['train'].features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0358010e-da9b-4396-8e58-77555b7984ac",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c777240-5a70-4507-bf89-ce499ea16e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels\n",
    "if task_name is not None:\n",
    "    is_regression = task_name == \"stsb\"\n",
    "    if not is_regression:\n",
    "        label_list = datasets[\"train\"].features[\"label\"].names\n",
    "        num_labels = len(label_list)\n",
    "    else:\n",
    "        num_labels = 1\n",
    "else:\n",
    "    # Trying to have good defaults here, don't hesitate to tweak to your needs.\n",
    "    is_regression = datasets[\"train\"].features[\"label\"].dtype in [\"float32\", \"float64\"]\n",
    "    if is_regression:\n",
    "        num_labels = 1\n",
    "    else:\n",
    "        # A useful fast method:\n",
    "        # https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.unique\n",
    "        label_list = datasets[\"train\"].unique(\"label\")\n",
    "        label_list.sort()  # Let's sort it for determinism\n",
    "        num_labels = len(label_list)\n",
    "        \n",
    "num_labels, is_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d8a28a-830f-47ac-b816-d91d95bb0819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer, PretrainedConfig\n",
    "model_name_or_path = \"bert-base-cased\"\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    num_labels=num_labels, \n",
    "    finetuning_task=task_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_name_or_path),\n",
    "    config=config,\n",
    ")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=num_labels)\n",
    "label_to_id = None\n",
    "\n",
    "if (\n",
    "    model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id\n",
    "    and task_name is not None\n",
    "    and not is_regression\n",
    "):\n",
    "    # Some have all caps in their config, some don't.\n",
    "    label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}\n",
    "    if list(sorted(label_name_to_id.keys())) == list(sorted(label_list)):\n",
    "        label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}\n",
    "        \n",
    "elif task_name is None and not is_regression:\n",
    "    label_to_id = {v: i for i, v in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10576f7-4221-449b-bcdd-1c3cd721a1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/todsavadt/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-02f69511fecf16e0.arrow\n",
      "Loading cached processed dataset at /home/todsavadt/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-5b57481bcffd58ce.arrow\n",
      "Loading cached processed dataset at /home/todsavadt/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-0c28ff668309d899.arrow\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    sentence1_key, sentence2_key = task_to_keys[task_name]\n",
    "    args = (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "    result = tokenizer(*args, max_length=180, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    # if label_to_id is not None and \"label\" in examples:\n",
    "    #     result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "\n",
    "    if \"label\" in examples:\n",
    "        if label_to_id is not None:\n",
    "            # Map labels to IDs (not necessary for GLUE tasks)\n",
    "            result[\"label\"] = [label_to_id[l] for l in examples[\"label\"]]\n",
    "        else:\n",
    "            # In all cases, rename the column to labels because the model will expect that.\n",
    "            result[\"label\"] = examples[\"label\"]\n",
    "    \n",
    "    return result\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "758c2756-4165-45ea-8924-a64d0391c17f",
   "metadata": {},
   "source": [
    "If you like, you can create a smaller subset of the full dataset to fine-tune on to reduce the time it takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a3d364-9467-49c7-b06e-0044d66f74c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5749\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1379\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4ea81fb-834e-47e2-8846-029da8dceaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5749\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1379\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(list(task_to_keys[task_name]) + [\"idx\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3dd9941-2127-468b-bd40-327cac9984da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/todsavadt/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a162f21ce968cedb.arrow\n",
      "Loading cached shuffled indices for dataset at /home/todsavadt/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ece2296a3dfbde6e.arrow\n",
      "Loading cached shuffled indices for dataset at /home/todsavadt/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f9ac64ab64dddc94.arrow\n"
     ]
    }
   ],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42) #.select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"validation_matched\" if task_name == \"mnli\" else \"validation\"].shuffle(seed=42) #.select(range(100))\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce7da51e-698c-499f-8ea9-f73d65a5dbfa",
   "metadata": {},
   "source": [
    "## 3. Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2354a20-bae4-43e5-9ddd-5f6dff62f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=16)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "731e14c1-f519-4657-bb47-46a52fa902b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0670, 0.1180, 0.1430, 0.1700, 0.2000, 0.2310, 0.2500, 0.3330,\n",
       "         0.4000, 0.4170, 0.5000, 0.6000, 0.6430, 0.6670, 0.7270, 0.7500, 0.8000,\n",
       "         0.8330, 0.8500, 0.8890, 0.9000, 0.9440, 1.0000, 1.1000, 1.2000, 1.2500,\n",
       "         1.2730, 1.2860, 1.3330, 1.4000, 1.5000, 1.5333, 1.5560, 1.5830, 1.6000,\n",
       "         1.6430, 1.6670, 1.7000, 1.7330, 1.7500, 1.7780, 1.8000, 1.8460, 2.0000,\n",
       "         2.1111, 2.2000, 2.2500, 2.3300, 2.3330, 2.3750, 2.4000, 2.4667, 2.5000,\n",
       "         2.5330, 2.5830, 2.5880, 2.6000, 2.6250, 2.6470, 2.6670, 2.7000, 2.7500,\n",
       "         2.7690, 2.8000, 2.8180, 2.8300, 2.8750, 2.9090, 2.9170, 3.0000, 3.0560,\n",
       "         3.0670, 3.1000, 3.1110, 3.1670, 3.2000, 3.2310, 3.2500, 3.2730, 3.3330,\n",
       "         3.3333, 3.4000, 3.4380, 3.4440, 3.4550, 3.5000, 3.5330, 3.6000, 3.6150,\n",
       "         3.6250, 3.6430, 3.6670, 3.6700, 3.6920, 3.7500, 3.7650, 3.7690, 3.7778,\n",
       "         3.7860, 3.8000, 3.8330, 3.8460, 3.8570, 3.8670, 3.8750, 3.9090, 3.9230,\n",
       "         3.9290, 3.9330, 3.9380, 3.9410, 4.0000, 4.0560, 4.0910, 4.1000, 4.1330,\n",
       "         4.1760, 4.2000, 4.2500, 4.3080, 4.3300, 4.3330, 4.3640, 4.4000, 4.5000,\n",
       "         4.5710, 4.5714, 4.6000, 4.6670, 4.7270, 4.7500, 4.7780, 4.8000, 4.8180,\n",
       "         4.8570, 4.8750, 4.9090, 4.9230, 5.0000]),\n",
       " tensor([0.0000, 0.0830, 0.1000, 0.2000, 0.2500, 0.4000, 0.5000, 0.6000, 0.6360,\n",
       "         0.6700, 0.7500, 0.7780, 0.8000, 0.8330, 1.0000, 1.1540, 1.2000, 1.2500,\n",
       "         1.3000, 1.3330, 1.4000, 1.5000, 1.5330, 1.5830, 1.6000, 1.6670, 1.6700,\n",
       "         1.7140, 1.7500, 1.8000, 1.9170, 2.0000, 2.1670, 2.2000, 2.2500, 2.3330,\n",
       "         2.3333, 2.3750, 2.4000, 2.5000, 2.6000, 2.6150, 2.6920, 2.7500, 2.8000,\n",
       "         2.8120, 3.0000, 3.0910, 3.1000, 3.2000, 3.2500, 3.3330, 3.4000, 3.4170,\n",
       "         3.5000, 3.6000, 3.6670, 3.6920, 3.7140, 3.7500, 3.8000, 3.8240, 4.0000,\n",
       "         4.1110, 4.2000, 4.2140, 4.2500, 4.3330, 4.4000, 4.4290, 4.5000, 4.6000,\n",
       "         4.6670, 4.7500, 4.8000, 4.8570, 4.9090, 5.0000]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train_dataset['labels'].unique(), small_eval_dataset['labels'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c0dabd8-a04d-43e7-8367-fa48a2db7e78",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39ee2222-9c96-4b69-a796-64a5143fbb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "# model_name_or_path = \"bert-base-cased\"\n",
    "# config = AutoConfig.from_pretrained(\n",
    "#     model_name_or_path, \n",
    "#     num_labels=num_labels, \n",
    "#     finetuning_task=task_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     model_name_or_path,\n",
    "#     from_tf=bool(\".ckpt\" in model_name_or_path),\n",
    "#     config=config,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e2b2e97-44f0-4421-ad27-9f928bd0a805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original parameters : 108311041\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "# config = AutoConfig.from_pretrained(\"bert-base-cased\", \n",
    "#                                     num_labels=num_labels, \n",
    "#                                     finetuning_task=task_name)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", \n",
    "#                                                            config=config)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Original parameters :', count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35013a64-9719-4b8b-bbac-1445fdab4d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technique : Adapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertAdapterModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1485889 || all params: 109796161 || trainable%: 1.3533159870680724\n"
     ]
    }
   ],
   "source": [
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    TaskType,\n",
    "    PrefixTuningConfig,\n",
    "    PromptEncoderConfig,\n",
    "    LoraConfig,\n",
    ")\n",
    "id2label = None\n",
    "PEFTtechnique = 'Adapter'\n",
    "print(f'Technique : {PEFTtechnique}')\n",
    "if PEFTtechnique == 'FT':\n",
    "    pass\n",
    "elif PEFTtechnique == 'Adapter':\n",
    "    #!pip install -U adapter-transformers\n",
    "    from transformers.adapters import BertAdapterModel, AutoAdapterModel \n",
    "    model = BertAdapterModel.from_pretrained(\"bert-base-cased\", num_labels=num_labels) \n",
    "    # Add a new adapter\n",
    "    model.add_adapter(task_name)\n",
    "    # Add a matching classification head\n",
    "    model.add_classification_head(\n",
    "        task_name,\n",
    "        num_labels=num_labels,\n",
    "        id2label=id2label\n",
    "      )\n",
    "    # Activate the adapter\n",
    "    model.train_adapter(task_name)\n",
    "    \n",
    "    def print_trainable_parameters(model):\n",
    "        \"\"\"\n",
    "        Prints the number of trainable parameters in the model.\n",
    "        \"\"\"\n",
    "        trainable_params = 0\n",
    "        all_param = 0\n",
    "        for _, param in model.named_parameters():\n",
    "            num_params = param.numel()\n",
    "            # if using DS Zero 3 and the weights are initialized empty\n",
    "            if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
    "                num_params = param.ds_numel\n",
    "\n",
    "            all_param += num_params\n",
    "            if param.requires_grad:\n",
    "                trainable_params += num_params\n",
    "        print(\n",
    "            f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "        )\n",
    "        \n",
    "    print_trainable_parameters(model) \n",
    "elif PEFTtechnique == 'Prefix':\n",
    "    peft_config = PrefixTuningConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=20, encoder_hidden_size=128)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters() \n",
    "elif PEFTtechnique == 'Prompt':\n",
    "    peft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=20, encoder_hidden_size=128)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters() \n",
    "elif PEFTtechnique == 'LoRA':\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS, inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "    )\n",
    "    \n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters() \n",
    "elif PEFTtechnique == 'BitFit':\n",
    "    # Freeze all parameters except biases\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'bias' not in name:\n",
    "            param.requires_grad = False "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc141bd1-58d8-4d92-84c7-71ae8f25a731",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9c0616a-f698-4d3c-b71e-9a70a9976c21",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Then we will need an optimizer. Weâ€™ll use the classic `AdamW`, which is like `Adam`, but with a fix in the way weight decay is applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35a8149d-e5c3-4e68-b77e-54515184136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1af7808a-ac83-4dd7-8357-a8d808c2faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0127d8fc-28eb-49b1-8e8b-618ed90a48f7",
   "metadata": {},
   "source": [
    "### Accelerator\n",
    "\n",
    "Once we have all those objects, we can send them to the `accelerator.prepare()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8e998f8-8cb1-4284-91f3-1b4841c42bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1ae728b-6991-4eae-bfa0-4e775d10ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3f84467-5090-4aa4-88c6-01a4c8d4a459",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a0240da-5ac4-4879-89e9-f6711450b632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144620/3036536553.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"glue\", task_name)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# metric = load_metric(\"mse\")\n",
    "metric = load_metric(\"glue\", task_name)\n",
    "# metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f65e410-32d4-4b1a-8fe0-4dd1592b7338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 363/1800 [00:36<12:25,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 1: {'pearson': 0.8398243641978261, 'spearmanr': 0.8349196562581404}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 723/1800 [01:12<09:24,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 2: {'pearson': 0.8632688548550549, 'spearmanr': 0.8598282563134325}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 897/1800 [01:28<01:20, 11.18it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "eval_metrics = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        # batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        # loss.backward()\n",
    "        accelerator.backward(loss)\n",
    "        # Step with optimizer\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        # batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "    \n",
    "        predictions = outputs.logits #.argmax(dim=-1)\n",
    "        # predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(\n",
    "            predictions=accelerator.gather(predictions), \n",
    "            references=accelerator.gather(batch[\"labels\"])\n",
    "        )\n",
    "        \n",
    "    eval_metric = metric.compute()\n",
    "    eval_metrics += eval_metric['pearson'] \n",
    "    print(f\"Epoch at {epoch+1}: {eval_metric}\")\n",
    "print('Avg Metric', eval_metrics/num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06117d-aa92-41d9-b16e-319b076adfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
